# einsum
- [einsum](#einsum)
  - [matrix transpose 矩阵转置](#matrix-transpose-矩阵转置)
  - [sum 矩阵内元素求和](#sum-矩阵内元素求和)
    - [全体求和](#全体求和)
    - [行求和](#行求和)
    - [列求和](#列求和)
  - [matrix-vector multiplication](#matrix-vector-multiplication)
  - [matrix-matrix multiplication](#matrix-matrix-multiplication)
  - [dot product 元素点积(向量/矩阵/高维)](#dot-product-元素点积向量矩阵高维)
    - [向量点积](#向量点积)
    - [矩阵点积](#矩阵点积)
    - [高维点积](#高维点积)
  - [哈达玛积 基本积 HADAMARD PRODUCT](#哈达玛积-基本积-hadamard-product)
  - [外积 outer product](#外积-outer-product)
  - [batch化处理](#batch化处理)
  - [广义矩阵相乘](#广义矩阵相乘)
  - [维度省略](#维度省略)


Einsum在numpy(np.einsum)、pytorch(torch.einsum)、tensorflow(tf.einsum)中都有实现。  
函数签名均为einsum(equation, *inpus)，其中equation是一个string对象，代表了爱因斯坦计算如何进行；inputs代表一个或者多个tensor/ndarray对象。  
更重要的是，einsum可以进行graph的构建，并且可以进行梯度反向传播过程。  

样例采用torch1.13版本，但是各个api都完全一样，只是动态图容易学习。  

## matrix transpose 矩阵转置
```python
a = torch.arange(6).resize(2, 3)  # [2, 3]
trans_a = torch.einsum('ij->ji', a)  # [3, 2]

"""
tensor([[0, 1, 2],
        [3, 4, 5]])

tensor([[0, 3],
        [1, 4],
        [2, 5]])
"""
```

## sum 矩阵内元素求和
### 全体求和
```python
a = torch.arange(6).resize(2, 3)  # [2, 3]
trans_a = torch.einsum('ij->', a)  # []

"""
tensor([[0, 1, 2],
        [3, 4, 5]])

tensor(15)
"""
```
### 行求和
```python
a = torch.arange(6).resize(2, 3)  # [2, 3]
trans_a = torch.einsum('ij->i', a)  # [2]

"""
tensor([[0, 1, 2],
        [3, 4, 5]])

tensor([3, 12])
"""
```
### 列求和
```python
a = torch.arange(6).resize(2, 3)  # [2, 3]
trans_a = torch.einsum('ij->j', a)  # [3]

"""
tensor([[0, 1, 2],
        [3, 4, 5]])

tensor([3, 5, 7])
"""
```
## matrix-vector multiplication
[i, j]的矩阵A和[j]的向量B相乘，得到为[i]的向量。  
该过程可以理解为将B变为[j, 1]，而后矩阵相乘得到[i, 1]，之后去掉第二维得到[i]的向量
```python
a = torch.arange(6).resize(2, 3)  # [2, 3]
print(a)
b = torch.arange(3)  # [3]
print(b)
torch.einsum('ij, j->i', a, b)  # [2]

"""
tensor([[0, 1, 2],
        [3, 4, 5]])

tensor([0, 1, 2])

tensor([5, 14])
"""
```

## matrix-matrix multiplication
矩阵相乘 [i, j] * [j, k] -> [i, k]
```python
a = torch.arange(6).resize(2, 3)  # [2, 3]
print(a)
b = torch.arange(15).resize(3, 4)  # [3, 4]
print(b)
torch.einsum('ij,jk->ik', a, b)  # [2, 4]

"""
tensor([[0, 1, 2],
        [3, 4, 5]])

tensor([[0, 1, 2, 3],
        [4, 5, 6, 7],
        [8, 9, 10, 11]])

tensor([[20, 23, 26, 29],
        [56, 68, 80, 92]])
"""
```
## dot product 元素点积(向量/矩阵/高维)
### 向量点积
```python
a = torch.arange(3)  # [3]
print(a)
b = torch.arange(3, 6)  # [3]
print(b)
torch.einsum('i, i->', a, b)  # []

"""
tensor([0, 1, 2])

tensor([3, 4, 5])

tensor(14)
"""
```
### 矩阵点积
```python
a = torch.arange(10).resize(2, 5)  # [2, 5]
print(a)
b = torch.arange(10, 20).resize(2, 5)  # [2, 5]
print(b)
torch.einsum('ij, ij->', a, b)  # []

"""
tensor([[0, 1, 2, 3, 4],
        [5, 6, 7, 8, 9]])

tensor([[10, 11, 12, 13, 14],
        [15, 16, 17, 18, 19]])

tensor(735)
```
### 高维点积
```python
a = torch.arange(8).resize(2, 2, 2)  # [2, 2, 2]
print(a)
b = torch.arange(8, 16).resize(2, 2, 2)  # [2, 2, 2]
print(b)
torch.einsum('ijk, ijk->', a, b)  # []

"""
tensor([[[0, 1],
       [2, 3]],
       [[4, 5],
       [6, 7]]])

tensor([[[8, 9],
       [10, 11]],
       [[12, 13],
       [14, 15]]])

tensor(364)
```

## 哈达玛积 基本积 HADAMARD PRODUCT
哈达玛积是两个维度相同的矩阵进行按位置乘法，最终得到的结果维度不变。  
```python
a = torch.arange(6).resize(2, 3)  # [2, 3]
print(a)
b = torch.arange(6, 12).resize(2, 3)  # [2, 3]
print(b)
torch.einsum('ij, ij-> ij', a, b)  # [2, 3]

"""
tensor([[0, 1, 2],
        [3, 4, 5]])

tensor([[6, 7, 8],
        [9, 10, 11]])

tensor([[0, 7, 16],
        [27, 48, 55]])
"""
```

## 外积 outer product
outer product 将[i]的向量A和[j]的向量B，得到矩阵C[i, j] C(i, j)=A(i)*B(j)
```python
a = torch.arange(1, 4)  # [3]
b = torch.arange(4, 7)  # [3]
c = torch.einsum('i,j->ij', a, b)

"""
tensor([1, 2, 3])

tensor([4, 5, 6])

tensor([[4, 5, 6],
        [8, 10, 12],
        [12, 15, 18]])
"""
```

## batch化处理
```python
batch = 2
a = torch.arange(12).resize(2, 2, 3)
b = torch.arange(24).resize(2, 3, 4)
c = torch.einsum('ijk, ikl-> ijl', a, b)
```

## 广义矩阵相乘
矩阵相乘可以理解为[i, j] * [j, k] -> [i, k]，其中i, j, k 都是标量数值。  
若将i j k 考虑为多个标量数字，如i为[2, 3] j为[5, 7] k 为[5, 3]， 那么矩阵相乘得到结果为[2, 3, 5, 3]  
```python
a = torch.randn((2, 3, 5, 7))
b = torch.randn((5, 7, 5, 3))
c = torch.einsum('pqrs, rsuv -> pquv', a, b)  # [2, 3, 5, 3]
```
若额外带有转置的话，同样可以使用einsum简易处理。  
在打乱维度顺序进行矩阵相乘时，可以想象为进行转置后进行广义矩阵相乘。  
```python
a = torch.randn((2, 3, 5, 7))
b = torch.randn((11, 13, 3, 17, 5))

c = torch.einsum('pqrs, tuqvr -> pstuv', a, b)
# 3, 5分别用q r代表，进行矩阵相乘 其他部分顺序放置
```

## 维度省略
在einsum中，可以使用"..."省略前方的维度，使得表达式更高效，可读性更强
```python
a = torch.arange(12).resize(1, 2, 2, 3)
b = torch.arange(24).resize(1, 2, 3, 4)

c = torch.einsum('...ij, ...jk-> ...ik', a, b)  # [1, 2, 2, 4]
```