{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'ML_tools/NLP/sentencepiece/data_dir/'\n",
    "os.path.exists(data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_dev_raw_zh = os.path.join(data_dir,'train_dev.raw.zh')\n",
    "train_dev_raw_en = os.path.join(data_dir,'train_dev.raw.en')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------粗略查看中英文情况------------------------------\n",
      "----------------------------------中文文字情况------------------------------\n",
      "非常謝謝你，克里斯。能有這個機會第二度踏上這個演講台\n",
      "\n",
      "真是一大榮幸。我非常感激。\n",
      "\n",
      "這個研討會給我留下了極為深刻的印象，我想感謝大家 對我之前演講的好評。\n",
      "\n",
      "我是由衷的想這麼說，有部份原因是因為 —— 我真的有需要!\n",
      "\n",
      "請你們設身處地為我想一想！\n",
      "\n",
      "我曾搭乘副總統專機八年。\n",
      "\n",
      "現在我卻必須脫了鞋子才能上飛機!\n",
      "\n",
      "讓我跟你們說一個很短的故事，你們就會明白我的日子是怎麼過的。\n",
      "\n",
      "這是一個真實的故事 — 徹頭徹尾都是真實的。\n",
      "\n",
      "在我跟我夫人蒂佩爾離開 —— 白宮 —— 後 我們從那什維爾的家開車到 東邊 50 英哩外的一個我們擁有的小農場 —\n",
      "\n",
      "----------------------------------英文文字情况------------------------------\n",
      "Thank you so much, Chris.\n",
      "\n",
      "And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\n",
      "\n",
      "I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night.\n",
      "\n",
      "And I say that sincerely, partly because  I need that.\n",
      "\n",
      "Put yourselves in my position.\n",
      "\n",
      "I flew on Air Force Two for eight years.\n",
      "\n",
      "Now I have to take off my shoes or boots to get on an airplane!\n",
      "\n",
      "I'll tell you one quick story to illustrate what that's been like for me.\n",
      "\n",
      "It's a true story -- every bit of this is true.\n",
      "\n",
      "Soon after Tipper and I left the --  White House --  we were driving from our home in Nashville to a little farm we have 50 miles east of Nashville.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------------粗略查看中英文情况------------------------------')\n",
    "count = 0\n",
    "test_zh_list = list()\n",
    "with open(train_dev_raw_zh, 'r') as file:\n",
    "    for line in file:\n",
    "        if count == 10:\n",
    "            break\n",
    "        test_zh_list.append(line)\n",
    "        count = count + 1\n",
    "print('----------------------------------中文文字情况------------------------------')\n",
    "for each_zh in test_zh_list:\n",
    "    print(each_zh)\n",
    "\n",
    "count = 0\n",
    "test_en_list = list()\n",
    "with open(train_dev_raw_en, 'r') as file:\n",
    "    for line in file:\n",
    "        if count == 10:\n",
    "            break\n",
    "        test_en_list.append(line)\n",
    "        count = count + 1\n",
    "print('----------------------------------英文文字情况------------------------------')\n",
    "for each_en in test_en_list:\n",
    "    print(each_en)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## step1 Q2B\n",
    "中文的标点符号 空格等内容都是全角字 要先将其转化为半角字"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def strQ2B(ustring):\n",
    "    # 全角字变半角字\n",
    "    # 对字母 数字 标点符号 从全角字转成半角字\n",
    "    ss = []\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # Full width space: direct conversion\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # Full width chars (except space) conversion\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss.append(rstring)\n",
    "    return ''.join(ss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## step2 去除符号 统一处理标点符号"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def clean_s(s, lang):\n",
    "    \"\"\"\n",
    "    清洗中英字符串\n",
    "    :param s:  string 代表每个句子\n",
    "    :param lang: string 取值为zh-en 代表语言\n",
    "    :return: 清洗过后的string句子\n",
    "    \"\"\"\n",
    "    if lang == 'en':\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])         # 去掉([text])这个模式的文本\n",
    "        s = s.replace('-', '') # remove '-'                        # 去掉-\n",
    "        s = re.sub('([.,;!?()\\\"])', r' \\1 ', s) # keep punctuation # 保留标点符号 在前后加上空格成为一个word\n",
    "    elif lang == 'zh':\n",
    "        s = strQ2B(s) # Q2B\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])        # 去掉([text])这个模式的文本\n",
    "        s = s.replace(' ', '')\n",
    "        s = s.replace('—', '')\n",
    "        s = s.replace('“', '\"')\n",
    "        s = s.replace('”', '\"')\n",
    "        s = s.replace('_', '')                                    # 去掉 tab “ — _\n",
    "        s = re.sub('([。,;!?()\\\"~「」])', r' \\1 ', s) # keep punctuation # 保留标点符号 在前后加上空格成为一个word\n",
    "    s = ' '.join(s.strip().split())\n",
    "    return s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## step3 按照长度进行限制 进行清洗"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def len_s(s, lang):\n",
    "    \"\"\"\n",
    "    返回句子的长度(词的个数) 中文就是直接返回长度 英文是要通过空格分隔之后返回长度\n",
    "    :param s: string句子文本\n",
    "    :param lang: 语言类型\n",
    "    :return: 句子长度\n",
    "    \"\"\"\n",
    "    if lang == 'zh':\n",
    "        return len(s)\n",
    "    return len(s.split())\n",
    "\n",
    "def clean(l1, l2, max_len = 1000, min_len = 1, ratio = 9):\n",
    "    \"\"\"\n",
    "    清洗语句\n",
    "    :param l1: language1\n",
    "    :param l2: language2\n",
    "    :param max_len: 限制文本最大长度 大于该长度舍弃\n",
    "    :param min_len: 限制文本最小长度 小于改长度舍弃\n",
    "    :param ratio: 当两个语言的文本长度差异过大 比值大于ratio时 舍弃\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if os.path.exists(os.path.join(data_dir, 'train_dev.clean.{}'.format(l1))) \\\n",
    "            and os.path.exists(os.path.join(data_dir, 'train_dev.clean.{}'.format(l2))):\n",
    "        print('{} and {} clean file exists.'.format(l1, l2))\n",
    "        return\n",
    "    # 如果存在l1和l2的clean 文件 就跳过该函数\n",
    "\n",
    "    with open(os.path.join(data_dir, 'train_dev.raw.{}'.format(l1)), 'r') as l1_raw_file:\n",
    "        with open(os.path.join(data_dir, 'train_dev.raw.{}'.format(l2)), 'r') as l2_raw_file:\n",
    "            with open(data_dir + 'train_dev.clean.{}'.format(l1), 'w') as l1_clean_file:\n",
    "                with open(data_dir + 'train_dev.clean.{}'.format(l2), 'w') as l2_clean_file:\n",
    "                    for s1 in l1_raw_file: # for 就相当于readline()\n",
    "                        s1 = s1.strip()\n",
    "                        s2 = l2_raw_file.readline().strip() # s2 直接readline\n",
    "                        s1 = clean_s(s1, l1)\n",
    "                        s2 = clean_s(s2, l2)\n",
    "                        s1_len = len_s(s1, l1)\n",
    "                        s2_len = len_s(s2, l2)\n",
    "                        if min_len > 0:\n",
    "                            if s1_len < min_len or s2_len < min_len: # 删除长度小于min_len的部分\n",
    "                                continue\n",
    "                        if max_len > 0:\n",
    "                            if s1_len > max_len or s2_len > max_len: # 删除长度大于max_len的部分\n",
    "                                continue\n",
    "                        if ratio > 0:\n",
    "                            if s1_len / s2_len > ratio or s2_len / s1_len > ratio: # 删除长度比值大于ration的部分\n",
    "                                continue\n",
    "                        print(s1, file = l1_clean_file)\n",
    "                        print(s2, file = l2_clean_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "clean(l1 = 'zh', l2 = 'en')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## step4 sentencepiece处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def train_sentence_model(vocab_size, l1, l2):\n",
    "    if os.path.exists(os.path.join(data_dir, 'spm{}.model'.format(vocab_size))):\n",
    "        print('spm{}.model'.format(vocab_size) + ' exists.')\n",
    "        return\n",
    "\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input =','.join([\n",
    "            os.path.join(data_dir, 'train_dev.clean.{}'.format(l1)),\n",
    "            os.path.join(data_dir, 'train_dev.clean.{}'.format(l2))\n",
    "        ]),\n",
    "        model_prefix = os.path.join(data_dir, 'spm{}.model'.format(vocab_size)), # 输出文件路径\n",
    "        vocab_size = vocab_size, # 词汇表大小\n",
    "        character_coverage = 0.9995, # 模型覆盖的字符数量 对于有丰富字符集的如中文 合适的默认值是0.9995\n",
    "        model_type = 'bpe', # 模式是bpe\n",
    "        input_sentence_size=1e6, #\n",
    "        shuffle_input_sentence=True, # 随机采样输入\n",
    "        normalization_rule_name='nmt_nfkc_cf', # 正则化方法\n",
    "    )\n",
    "train_sentence_model(vocab_size=8000, l1 = 'zh', l2 = 'en')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "spm_model = spm.SentencePieceProcessor(model_file = os.path.join(data_dir, 'spm{}.model.model'.format(8000)))\n",
    "def transform_with_spm_model(l1, l2):\n",
    "    if os.path.exists(os.path.join(data_dir, 'train_dev.final.{}'.format(l1))) \\\n",
    "        and os.path.exists(os.path.join(data_dir, 'train_dev.final.{}'.format(l2))):\n",
    "        print('{} and {} final file exists.'.format(l1, l2))\n",
    "        return\n",
    "\n",
    "    language_list = [l1, l2]\n",
    "    for lang in language_list:\n",
    "        with open(os.path.join(data_dir, 'train_dev.final.{}'.format(lang)), 'w') as final_file:\n",
    "            with open(os.path.join(data_dir, 'train_dev.clean.{}'.format(lang)), 'r') as clean_file:\n",
    "                for line in clean_file:\n",
    "                    line = line.strip()\n",
    "                    tok = spm_model.encode(line, out_type = str)\n",
    "                    print(' '.join(tok), file = final_file)\n",
    "transform_with_spm_model('zh', 'en')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}